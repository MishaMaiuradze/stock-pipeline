version: '3.8'

services:
  # Kafka broker (KRaft mode - no Zookeeper)
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "${KAFKA_PORT}:9092"
      - "${KAFKA_CONTROLLER_PORT}:9093"
    environment:
      KAFKA_NODE_ID: ${KAFKA_NODE_ID}
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_NODE_ID}@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS}
      CLUSTER_ID: ${CLUSTER_ID}
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - stock-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # PostgreSQL Database
  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT_EXTERNAL}:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - stock-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d stock_data"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Apache Spark Master
  spark-master:
    build:
      context: ./spark-master
      dockerfile: Dockerfile
    container_name: spark-master
    ports:
      - "${SPARK_MASTER_WEB_PORT}:8080"
      - "${SPARK_MASTER_PORT}:7077"
    volumes:
      - spark-apps:/opt/spark-apps
      - spark-data:/opt/spark-data
    networks:
      - stock-network
    environment:
      - SPARK_NO_DAEMONIZE=true

  # Apache Spark Worker
  spark-worker:
    build:
      context: ./spark-master
      dockerfile: Dockerfile
    container_name: spark-worker
    depends_on:
      - spark-master
    volumes:
      - spark-apps:/opt/spark-apps
      - spark-data:/opt/spark-data
    networks:
      - stock-network
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_MASTER=spark://spark-master:7077
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # Binance Data Producer
  binance-producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: binance-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: ${KAFKA_TOPIC}
      BINANCE_SYMBOLS: ${BINANCE_SYMBOLS}
      LOG_LEVEL: ${LOG_LEVEL}
    networks:
      - stock-network
    restart: unless-stopped

  # Kafka Consumer (Real-time Stream Processor)
  kafka-consumer:
    build:
      context: ./kafka-consumer
      dockerfile: Dockerfile
    container_name: kafka-consumer
    depends_on:
      - kafka
      - postgres
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC: ${KAFKA_TOPIC}
      KAFKA_GROUP_ID: ${KAFKA_GROUP_ID}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      LOG_LEVEL: ${LOG_LEVEL}
    networks:
      - stock-network
    restart: unless-stopped

  # Spark Batch Processor
  spark-processor:
    build:
      context: ./spark-processor
      dockerfile: Dockerfile
    container_name: spark-processor
    depends_on:
      - spark-master
      - postgres
    environment:
      SPARK_MASTER_URL: ${SPARK_MASTER_URL}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      LOG_LEVEL: ${LOG_LEVEL}
    volumes:
      - ./spark-processor:/app  # Mount for development (fast iteration)
      - spark-apps:/opt/spark-apps
    networks:
      - stock-network
    restart: unless-stopped

  # Apache Superset
  superset:
    image: apache/superset:3.1.0
    container_name: superset
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "${SUPERSET_PORT}:8088"
    volumes:
      - superset-data:/app/superset_home
      - ./superset-init:/app/docker-init
    networks:
      - stock-network
    command: >
      bash -c "
      pip install psycopg2-binary &&
      superset db upgrade &&
      superset fab create-admin --username ${SUPERSET_ADMIN_USERNAME} --firstname Admin --lastname User --email ${SUPERSET_ADMIN_EMAIL} --password ${SUPERSET_ADMIN_PASSWORD} &&
      superset init &&
      /usr/bin/run-server.sh
      "
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  stock-network:
    driver: bridge

volumes:
  kafka-data:
  postgres-data:
  spark-apps:
  spark-data:
  superset-data:
